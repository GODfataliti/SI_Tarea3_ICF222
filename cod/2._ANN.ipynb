{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2 (Ubuntu Linux)","language":"python","metadata":{"cocalc":{"description":"Python 2 programming language","priority":5,"url":"https://www.python.org/"}},"name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"},"colab":{"name":"2. ANN.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"xyOzIFYhvm84","executionInfo":{"status":"ok","timestamp":1606504304091,"user_tz":180,"elapsed":724,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKX10HPpvm89","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606504306431,"user_tz":180,"elapsed":728,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"40792d44-6e89-4d22-eccb-3fbb3ac34c3b"},"source":["df = pd.read_csv('Churn_Modelling.csv')\n","print(df.head())\n","X = df.iloc[:, 3:13].values\n","y = df.iloc[:, 13].values\n","print(X)\n","print(y)\n","print(X.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  \n","[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n","[1 0 1 ... 1 1 0]\n","(10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F5ZrVlnKvm9A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606505224046,"user_tz":180,"elapsed":1579,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"e8394270-a47a-4bde-c3a1-520b16403d59"},"source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","le_geography = LabelEncoder()\n","X[:, 1] = le_geography.fit_transform(X[:, 1])\n","le_gender = LabelEncoder()\n","X[:, 2] = le_gender.fit_transform(X[:, 2])\n","ohe = OneHotEncoder(categorical_features=[1])\n","X = ohe.fit_transform(X).toarray()\n","# evitar trampa de variable irrrelevante ;)\n","X = X[:, 1:]\n","print(X)\n","print(X.shape)\n","y.shape"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[[0.0000000e+00 0.0000000e+00 6.1900000e+02 ... 1.0000000e+00\n","  1.0000000e+00 1.0134888e+05]\n"," [0.0000000e+00 1.0000000e+00 6.0800000e+02 ... 0.0000000e+00\n","  1.0000000e+00 1.1254258e+05]\n"," [0.0000000e+00 0.0000000e+00 5.0200000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.1393157e+05]\n"," ...\n"," [0.0000000e+00 0.0000000e+00 7.0900000e+02 ... 0.0000000e+00\n","  1.0000000e+00 4.2085580e+04]\n"," [1.0000000e+00 0.0000000e+00 7.7200000e+02 ... 1.0000000e+00\n","  0.0000000e+00 9.2888520e+04]\n"," [0.0000000e+00 0.0000000e+00 7.9200000e+02 ... 1.0000000e+00\n","  0.0000000e+00 3.8190780e+04]]\n","(10000, 11)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n","  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"L7iBk4MTvm9D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606505947477,"user_tz":180,"elapsed":794,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"2b650fc4-7d60-4925-dee2-2c75b79e3a7f"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","print(X_train)\n","print(X_test)\n","print(type(X_train))\n","# print(X_train.shape)\n","# print(X_test-shape)\n","# 1). Hold-out: Dividir data de forma random en training-test (data muy grande)\n","# 2). (Stratified)K-Cross-Validation: Dividir data de forma random en K particiones balanceadas, se toman k-1 para training test y la restante para (data peque√±a (100 datos) - grande) - [K Random Hold-Out ]\n","# 3). Leave-One-Out=K-CV con K=N. [muy pocos datos]. Discutido si es mejor que K-CV HW: Bootstrapping"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[[0.0000000e+00 1.0000000e+00 6.6700000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.6383064e+05]\n"," [1.0000000e+00 0.0000000e+00 4.2700000e+02 ... 1.0000000e+00\n","  1.0000000e+00 5.7098000e+04]\n"," [0.0000000e+00 0.0000000e+00 5.3500000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.8563076e+05]\n"," ...\n"," [0.0000000e+00 0.0000000e+00 7.3800000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.8142987e+05]\n"," [0.0000000e+00 1.0000000e+00 5.9000000e+02 ... 1.0000000e+00\n","  1.0000000e+00 1.4875016e+05]\n"," [1.0000000e+00 0.0000000e+00 6.2300000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.1885526e+05]]\n","[[1.0000000e+00 0.0000000e+00 5.9700000e+02 ... 1.0000000e+00\n","  1.0000000e+00 1.9285267e+05]\n"," [0.0000000e+00 0.0000000e+00 5.2300000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.2870210e+05]\n"," [0.0000000e+00 1.0000000e+00 7.0600000e+02 ... 1.0000000e+00\n","  1.0000000e+00 7.5732250e+04]\n"," ...\n"," [0.0000000e+00 1.0000000e+00 5.7800000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.4153319e+05]\n"," [1.0000000e+00 0.0000000e+00 6.5000000e+02 ... 1.0000000e+00\n","  1.0000000e+00 1.1276480e+04]\n"," [1.0000000e+00 0.0000000e+00 5.7300000e+02 ... 1.0000000e+00\n","  0.0000000e+00 1.9295060e+05]]\n","<type 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KEAG6Xjdvm9G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606506302467,"user_tz":180,"elapsed":734,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"bfcce95f-e7a6-4286-e98a-a1bbb1091c1c"},"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler() #normalizacion Z\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","print(X_train)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[-0.5698444   1.74309049  0.16958176 ...  0.64259497 -1.03227043\n","   1.10643166]\n"," [ 1.75486502 -0.57369368 -2.30455945 ...  0.64259497  0.9687384\n","  -0.74866447]\n"," [-0.5698444  -0.57369368 -1.19119591 ...  0.64259497 -1.03227043\n","   1.48533467]\n"," ...\n"," [-0.5698444  -0.57369368  0.9015152  ...  0.64259497 -1.03227043\n","   1.41231994]\n"," [-0.5698444   1.74309049 -0.62420521 ...  0.64259497  0.9687384\n","   0.84432121]\n"," [ 1.75486502 -0.57369368 -0.28401079 ...  0.64259497 -1.03227043\n","   0.32472465]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0c7wd7Ylvm9K","executionInfo":{"status":"ok","timestamp":1606507927901,"user_tz":180,"elapsed":684,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}}},"source":["import keras #Wrapper de tensorflow\n","# import tensorflow\n","from keras.models import Sequential\n","from keras.layers import Dense #Full-connected\n","\n","# Crear clasificador ANN\n","classifier = Sequential()\n","# una regla de dedo gordo para determinar numero de nodos en capas ocultas (al comienzo) \n","# es usar el promedio de numero de nodos de entrada y salida\n","classifier.add(Dense(units=6, input_dim=11, kernel_initializer='uniform', activation='relu'))\n","# agregar segunda capa oculta\n","classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n","# capa de salida\n","# en este caso usar como funcion de activacion sigmoide ya que requerimos tener probabilidades de salida\n","classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) #Linear->regresion, relu->regresion (valores positivos)\n","# compile clasificador\n","# adam es una variante adaptiva de SGD\n","# crossentropy es la funcion de costo logaritmica de raices de Information Theory, para clasificacion binaria use 'binary_crossentropy' \n","# para clasificacion multiclase use 'categorical_crossentropy'\n","classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"p63KDB7Ivm9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606508045359,"user_tz":180,"elapsed":94504,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"0bc3199f-21a8-4e47-fe2a-ce6c5d064b14"},"source":["classifier.fit(X_train, y_train, epochs=100, batch_size=10)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.4300 - accuracy: 0.7960\n","Epoch 2/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4247 - accuracy: 0.7960\n","Epoch 3/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.4210 - accuracy: 0.8065\n","Epoch 4/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4180 - accuracy: 0.8229\n","Epoch 5/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4162 - accuracy: 0.8257\n","Epoch 6/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4148 - accuracy: 0.8300\n","Epoch 7/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.4130 - accuracy: 0.8306\n","Epoch 8/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.4120 - accuracy: 0.8322\n","Epoch 9/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.4104 - accuracy: 0.8335\n","Epoch 10/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4097 - accuracy: 0.8341\n","Epoch 11/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.4090 - accuracy: 0.8340\n","Epoch 12/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4077 - accuracy: 0.8324\n","Epoch 13/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.4073 - accuracy: 0.8351\n","Epoch 14/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.4058 - accuracy: 0.8355\n","Epoch 15/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.4058 - accuracy: 0.8355\n","Epoch 16/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.4054 - accuracy: 0.8357\n","Epoch 17/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.4041 - accuracy: 0.8353\n","Epoch 18/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.4032 - accuracy: 0.8344\n","Epoch 19/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.4019 - accuracy: 0.8361\n","Epoch 20/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.4009 - accuracy: 0.8344\n","Epoch 21/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.4004 - accuracy: 0.8360\n","Epoch 22/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3995 - accuracy: 0.8349\n","Epoch 23/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3992 - accuracy: 0.8366\n","Epoch 24/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3984 - accuracy: 0.8354\n","Epoch 25/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3981 - accuracy: 0.8355\n","Epoch 26/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3977 - accuracy: 0.8346\n","Epoch 27/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3968 - accuracy: 0.8334\n","Epoch 28/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3973 - accuracy: 0.8341\n","Epoch 29/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3971 - accuracy: 0.8347\n","Epoch 30/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3961 - accuracy: 0.8361\n","Epoch 31/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3963 - accuracy: 0.8374\n","Epoch 32/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3958 - accuracy: 0.8354\n","Epoch 33/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3956 - accuracy: 0.8367\n","Epoch 34/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3958 - accuracy: 0.8349\n","Epoch 35/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3955 - accuracy: 0.8363\n","Epoch 36/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3953 - accuracy: 0.8354\n","Epoch 37/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3952 - accuracy: 0.8364\n","Epoch 38/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3953 - accuracy: 0.8372\n","Epoch 39/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3949 - accuracy: 0.8370\n","Epoch 40/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3947 - accuracy: 0.8364\n","Epoch 41/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3941 - accuracy: 0.8363\n","Epoch 42/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3947 - accuracy: 0.8350\n","Epoch 43/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3946 - accuracy: 0.8371\n","Epoch 44/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3945 - accuracy: 0.8376\n","Epoch 45/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3940 - accuracy: 0.8365\n","Epoch 46/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3935 - accuracy: 0.8372\n","Epoch 47/100\n","8000/8000 [==============================] - 1s 113us/step - loss: 0.3941 - accuracy: 0.8382\n","Epoch 48/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3940 - accuracy: 0.8381\n","Epoch 49/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3935 - accuracy: 0.8363\n","Epoch 50/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3930 - accuracy: 0.8376\n","Epoch 51/100\n","8000/8000 [==============================] - 1s 123us/step - loss: 0.3918 - accuracy: 0.8359\n","Epoch 52/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3925 - accuracy: 0.8393\n","Epoch 53/100\n","8000/8000 [==============================] - 1s 120us/step - loss: 0.3922 - accuracy: 0.8386\n","Epoch 54/100\n","8000/8000 [==============================] - 1s 123us/step - loss: 0.3913 - accuracy: 0.8366\n","Epoch 55/100\n","8000/8000 [==============================] - 1s 125us/step - loss: 0.3892 - accuracy: 0.8381\n","Epoch 56/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3859 - accuracy: 0.8385\n","Epoch 57/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3830 - accuracy: 0.8405\n","Epoch 58/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3811 - accuracy: 0.8414\n","Epoch 59/100\n","8000/8000 [==============================] - 1s 131us/step - loss: 0.3791 - accuracy: 0.8418\n","Epoch 60/100\n","8000/8000 [==============================] - 1s 126us/step - loss: 0.3777 - accuracy: 0.8403\n","Epoch 61/100\n","8000/8000 [==============================] - 1s 133us/step - loss: 0.3770 - accuracy: 0.8388\n","Epoch 62/100\n","8000/8000 [==============================] - 1s 128us/step - loss: 0.3752 - accuracy: 0.8416\n","Epoch 63/100\n","8000/8000 [==============================] - 1s 132us/step - loss: 0.3756 - accuracy: 0.8405\n","Epoch 64/100\n","8000/8000 [==============================] - 1s 130us/step - loss: 0.3750 - accuracy: 0.8367\n","Epoch 65/100\n","8000/8000 [==============================] - 1s 131us/step - loss: 0.3744 - accuracy: 0.8386\n","Epoch 66/100\n","8000/8000 [==============================] - 1s 129us/step - loss: 0.3743 - accuracy: 0.8384\n","Epoch 67/100\n","8000/8000 [==============================] - 1s 128us/step - loss: 0.3738 - accuracy: 0.8389\n","Epoch 68/100\n","8000/8000 [==============================] - 1s 128us/step - loss: 0.3734 - accuracy: 0.8400\n","Epoch 69/100\n","8000/8000 [==============================] - 1s 129us/step - loss: 0.3730 - accuracy: 0.8410\n","Epoch 70/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3735 - accuracy: 0.8380\n","Epoch 71/100\n","8000/8000 [==============================] - 1s 121us/step - loss: 0.3733 - accuracy: 0.8389\n","Epoch 72/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3728 - accuracy: 0.8401\n","Epoch 73/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3721 - accuracy: 0.8382\n","Epoch 74/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3720 - accuracy: 0.8413\n","Epoch 75/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3719 - accuracy: 0.8393\n","Epoch 76/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3719 - accuracy: 0.8418\n","Epoch 77/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3723 - accuracy: 0.8395\n","Epoch 78/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3708 - accuracy: 0.8386\n","Epoch 79/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3710 - accuracy: 0.8399\n","Epoch 80/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3706 - accuracy: 0.8406\n","Epoch 81/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3708 - accuracy: 0.8395\n","Epoch 82/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3705 - accuracy: 0.8400\n","Epoch 83/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3703 - accuracy: 0.8414\n","Epoch 84/100\n","8000/8000 [==============================] - 1s 125us/step - loss: 0.3707 - accuracy: 0.8422\n","Epoch 85/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3695 - accuracy: 0.8400\n","Epoch 86/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3699 - accuracy: 0.8415\n","Epoch 87/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3702 - accuracy: 0.8395\n","Epoch 88/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3697 - accuracy: 0.8426\n","Epoch 89/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3687 - accuracy: 0.8410\n","Epoch 90/100\n","8000/8000 [==============================] - 1s 120us/step - loss: 0.3696 - accuracy: 0.8413\n","Epoch 91/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3689 - accuracy: 0.8413\n","Epoch 92/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3686 - accuracy: 0.8420\n","Epoch 93/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3687 - accuracy: 0.8430\n","Epoch 94/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3689 - accuracy: 0.8434\n","Epoch 95/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3683 - accuracy: 0.8434\n","Epoch 96/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3681 - accuracy: 0.8413\n","Epoch 97/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3686 - accuracy: 0.8435\n","Epoch 98/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3679 - accuracy: 0.8414\n","Epoch 99/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3682 - accuracy: 0.8440\n","Epoch 100/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3677 - accuracy: 0.8439\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f2e521ce590>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"7vYUws2Avm9S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606508190498,"user_tz":180,"elapsed":818,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"438f535c-d2d2-432f-c3d0-b0dfe26c7642"},"source":["from sklearn.metrics import confusion_matrix,accuracy_score\n","y_pred = classifier.predict(X_train)\n","y_pred = (y_pred > 0.5)\n","print confusion_matrix(y_train, y_pred)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[[6101  267]\n"," [ 997  635]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"15b8UVwtvm9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606507421442,"user_tz":180,"elapsed":750,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"040e719d-6bbf-455e-9cab-ae91c6f776b4"},"source":["(6368+0)/(6368.0+1632+0+0)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.796"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kRcdoujjvm9Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606508194662,"user_tz":180,"elapsed":754,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"ec253a5c-6b37-4c62-ac69-bdd8d4af966c"},"source":["print(accuracy_score(y_train,y_pred))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["0.842\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QnNESTEDP32v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606508201724,"user_tz":180,"elapsed":721,"user":{"displayName":"Billy Peralta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh44H8W3RxzAD9UnGnOW8cSfBxdEojiDSgtSQFoQ=s64","userId":"12826722639481736328"}},"outputId":"1bd01941-9a2c-42e8-8685-dee9f029148d"},"source":["y_predt = classifier.predict(X_test)\n","y_predt = (y_predt > 0.5)\n","print confusion_matrix(y_test, y_predt)\n","print accuracy_score(y_test,y_predt)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[[1525   70]\n"," [ 239  166]]\n","0.8455\n"],"name":"stdout"}]}]}